from app.modules.facts_check.web_search import search_with_serpapi
from app.modules.facts_check.llm_processing import (
    run_claim_extractor_sdk,
    run_fact_verifier_sdk
    )
import re
import time


def run_fact_check_pipeline(state):
    result = run_claim_extractor_sdk(state)

    if state.get("status") != "success":
        print("‚ùå Claim extraction failed.")
        return [], "Claim extraction failed."

    # Step 1: Extract claims
    raw_output = result.get("verifiable_claims", "")
    claims = re.findall(r"^[\*\-‚Ä¢]\s+(.*)", raw_output, re.MULTILINE)
    claims = [claim.strip() for claim in claims if claim.strip()]
    print(f"üß† Extracted claims: {claims}")

    if not claims:
        return [], "No verifiable claims found."

    # Step 2: Search each claim with polite delay
    search_results = []
    for claim in claims:
        print(f"\nüîç Searching for claim: {claim}")
        try:
            results = search_with_serpapi(claim, max_results=1)
            if results:
                results[0]["claim"] = claim
                search_results.append(results[0])
                print(f"‚úÖ Found result: {results[0]['title']}")
            else:
                print(f"‚ö†Ô∏è No search result for: {claim}")
        except Exception as e:
            print(f"‚ùå Search failed for: {claim} -> {e}")
        time.sleep(5)  # ‚è±Ô∏è Gentle delay to avoid DuckDuckGo ratelimit

    if not search_results:
        return [], "All claim searches failed or returned no results."

    # Step 3: Verify facts using LLM
    final = run_fact_verifier_sdk(search_results)
    return final.get("verifications", []), None
